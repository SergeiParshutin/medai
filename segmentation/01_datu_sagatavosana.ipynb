{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e73b78",
   "metadata": {},
   "source": [
    "# Glandu segmentācijas datu sagatavošana U-Net un FPN (segmentation_models_pytorch)\n",
    "\n",
    "Šajā notebook'ā mēs:\n",
    "\n",
    "- apskatīsim datu struktūru glandu segmentācijas datu kopai,\n",
    "- nolasīsim anotāciju JSON datnes un pārvērtīsim tās par bināru masku,\n",
    "- izveidosim `torch.utils.data.Dataset` klasi,\n",
    "- vizualizēsim dažus piemērus (attēls + maskas pārklājums),\n",
    "- sagatavosim visu tā, lai nākamajos piezīmjdatoros varētu:\n",
    "  - trenēt U-Net un FPN modeļus,\n",
    "  - salīdzināt to rezultātus.\n",
    "\n",
    "No sākuma datu struktūra ir šāda:\n",
    "\n",
    "``` bash\n",
    "data/\n",
    "  training/\n",
    "    img/*.bmp\n",
    "    ann/*.bmp.json\n",
    "  test/\n",
    "    img/*.bmp\n",
    "    ann/*.bmp.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d152324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importējam nepieciešamas bibliotēkas\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218bde18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saknes ceļš uz glandu datu kopu (pielāgo, ja vajag)\n",
    "GLAND_ROOT = Path(\"data/gland_seg\")\n",
    "\n",
    "TRAIN_DIR = GLAND_ROOT / \"training\"\n",
    "TEST_DIR = GLAND_ROOT / \"test\"\n",
    "\n",
    "print(\"Treniņa mape:\", TRAIN_DIR)\n",
    "print(\"Testa mape:\", TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atradīsim kādu vienu anotācijas datni, lai apskatītos struktūru\n",
    "sample_ann_files = list((TRAIN_DIR / \"ann\").glob(\"*.bmp.json\"))\n",
    "len(sample_ann_files), sample_ann_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apskatām pirmo anotāciju (strukturāli)\n",
    "sample_ann_path = sample_ann_files[0]\n",
    "print(\"Parauga anotācijas datne:\", sample_ann_path)\n",
    "\n",
    "with open(sample_ann_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    sample_ann = json.load(f)\n",
    "\n",
    "sample_ann.keys(), sample_ann.get(\"size\"), len(sample_ann.get(\"objects\", []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ac6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apskatām pirmo objektu paraugā\n",
    "first_obj = sample_ann[\"objects\"][0]\n",
    "first_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apskatām, kādas classTitle klases parādās datu kopā (pirmajiem N failiem)\n",
    "unique_classes = set()\n",
    "\n",
    "for ann_path in sample_ann_files[:50]:  # var palielināt, ja gribas pilnīgāk\n",
    "    with open(ann_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        ann = json.load(f)\n",
    "    for obj in ann.get(\"objects\", []):\n",
    "        unique_classes.add(obj.get(\"classTitle\", \"UNKNOWN\"))\n",
    "\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db43a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_mask_from_json(json_path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    No anotācijas JSON (Supervisely tipa poligoni) izveido bināru masku.\n",
    "    Rezultāts: maska ar izmēru (H, W), kur 1 = glands, 0 = fons.\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    h = data[\"size\"][\"height\"]\n",
    "    w = data[\"size\"][\"width\"]\n",
    "\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    for obj in data.get(\"objects\", []):\n",
    "        # Ja gribam filtrēt pēc konkrētās klases, var te ielikt if\n",
    "        # if obj[\"classTitle\"] not in [\"gland\", ...]: continue\n",
    "\n",
    "        points = obj[\"points\"][\"exterior\"]  # saraksts ar [x, y] punktiem\n",
    "        if len(points) < 3:\n",
    "            continue  # poligons ar < 3 punktiem nav jēdzīgs\n",
    "\n",
    "        # OpenCV fillPoly sagaida int32 masīvu formā (N,1,2)\n",
    "        pts = np.array(points, dtype=np.int32)\n",
    "        pts = pts.reshape((-1, 1, 2))\n",
    "\n",
    "        cv2.fillPoly(mask, [pts], 1)  # aizpildām poligonu ar vērtību 1\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Izvēlamies vienu attēlu+anotāciju no training\n",
    "img_name = sample_ann_path.stem        # \"12345.bmp\"\n",
    "sample_img_path = TRAIN_DIR / \"img\" / img_name\n",
    "print(\"Parauga attēls:\", sample_img_path)\n",
    "\n",
    "img = Image.open(sample_img_path).convert(\"RGB\")\n",
    "mask = create_binary_mask_from_json(sample_ann_path)\n",
    "\n",
    "img_np = np.array(img)\n",
    "print(\"Attēla forma:\", img_np.shape)\n",
    "print(\"Maskas forma:\", mask.shape, \"unikālās vērtības:\", np.unique(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizējam attēlu + masku\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Oriģinālais attēls\")\n",
    "plt.imshow(img_np)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Maska (bināra)\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Pārklājums (attēls + maska)\")\n",
    "overlay = img_np.copy()\n",
    "# padarīsim masku sarkanu\n",
    "red = overlay.copy()\n",
    "red[..., 0] = 255\n",
    "red[..., 1] = 0\n",
    "red[..., 2] = 0\n",
    "\n",
    "alpha = 0.5\n",
    "mask_3c = np.stack([mask]*3, axis=-1).astype(bool)\n",
    "overlay[mask_3c] = (alpha * red[mask_3c] + (1 - alpha) * overlay[mask_3c]).astype(np.uint8)\n",
    "\n",
    "plt.imshow(overlay)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlandSegmentationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset glandu segmentācijai.\n",
    "    Pieņem datu struktūru:\n",
    "\n",
    "      root/\n",
    "        training/\n",
    "          img/*.bmp\n",
    "          ann/*.bmp.json\n",
    "        test/\n",
    "          img/*.bmp\n",
    "          ann/*.bmp.json\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir: Path, split: str = \"training\", transform: Optional = None):\n",
    "        assert split in [\"training\", \"test\"], \"split jābūt 'training' vai 'test'\"\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        img_dir = self.root_dir / split / \"img\"\n",
    "        ann_dir = self.root_dir / split / \"ann\"\n",
    "\n",
    "        self.samples: List[Tuple[Path, Path]] = []\n",
    "\n",
    "        for img_path in sorted(img_dir.glob(\"*.bmp\")):\n",
    "            # \"12345.bmp\" -> \"12345.bmp.json\"\n",
    "            ann_path = ann_dir / f\"{img_path.name}.json\"\n",
    "            if not ann_path.exists():\n",
    "                # print(f\"[BRĪDINĀJUMS] Trūkst anotācijas priekš {img_path.name}\")\n",
    "                continue\n",
    "            self.samples.append((img_path, ann_path))\n",
    "\n",
    "        if not self.samples:\n",
    "            raise RuntimeError(f\"Neatradu nevienu attēla+anotācijas pāri mapē {img_dir}\")\n",
    "\n",
    "        print(f\"GlandSegmentationDataset ({split}): {len(self.samples)} paraugi.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path, ann_path = self.samples[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_np = np.array(img, dtype=np.float32) / 255.0  # (H,W,3)\n",
    "\n",
    "        mask_np = create_binary_mask_from_json(ann_path).astype(np.float32)  # (H,W)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=img_np, mask=mask_np)\n",
    "            img_np = transformed[\"image\"]\n",
    "            mask_np = transformed[\"mask\"]\n",
    "\n",
    "        img_tensor = torch.from_numpy(img_np).permute(2, 0, 1)  # (3,H,W)\n",
    "        mask_tensor = torch.from_numpy(mask_np).unsqueeze(0)    # (1,H,W)\n",
    "\n",
    "        return img_tensor, mask_tensor, img_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = GlandSegmentationDataset(GLAND_ROOT, split=\"training\", transform=None)\n",
    "test_ds = GlandSegmentationDataset(GLAND_ROOT, split=\"test\", transform=None)\n",
    "\n",
    "len(train_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paņemam dažus paraugus no treniņa kopas\n",
    "n_show = 3\n",
    "fig, axs = plt.subplots(n_show, 3, figsize=(12, 4 * n_show))\n",
    "\n",
    "for i in range(n_show):\n",
    "    img_t, mask_t, fname = train_ds[i]\n",
    "    img_np = img_t.permute(1, 2, 0).numpy()       # (H,W,3)\n",
    "    mask_np = mask_t.squeeze(0).numpy()           # (H,W)\n",
    "\n",
    "    axs[i, 0].imshow(img_np)\n",
    "    axs[i, 0].set_title(f\"{fname} - attēls\")\n",
    "    axs[i, 0].axis(\"off\")\n",
    "\n",
    "    axs[i, 1].imshow(mask_np, cmap=\"gray\")\n",
    "    axs[i, 1].set_title(\"Maska (0/1)\")\n",
    "    axs[i, 1].axis(\"off\")\n",
    "\n",
    "    # overlay\n",
    "    overlay = img_np.copy()\n",
    "    red = np.zeros_like(overlay)\n",
    "    red[..., 0] = 1.0\n",
    "    alpha = 0.5\n",
    "    mask3 = np.stack([mask_np]*3, axis=-1).astype(bool)\n",
    "    overlay[mask3] = alpha * red[mask3] + (1 - alpha) * overlay[mask3]\n",
    "\n",
    "    axs[i, 2].imshow(overlay)\n",
    "    axs[i, 2].set_title(\"Pārklājums (attēls + maska)\")\n",
    "    axs[i, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c883bf1",
   "metadata": {},
   "source": [
    "## Kopsavilkums\n",
    "\n",
    "- Datu kopa ir nolasīta no BMP attēliem un JSON anotācijām.\n",
    "- No anotācijām ģenerējam **bināru masku**: `1 = gland`, `0 = fons`.\n",
    "- Izveidota `GlandSegmentationDataset` klase, kas atgriež:\n",
    "  - `img_tensor`: `(3, H, W)`, `float32`, normalizēts [0,1],\n",
    "  - `mask_tensor`: `(1, H, W)`, `float32`, vērtības 0/1,\n",
    "  - faila nosaukumu, ko var izmantot debugam.\n",
    "\n",
    "Nākamais solis – **treniņa notebook**, kurā mēs:\n",
    "\n",
    "- izveidosim `DataLoader` treniņam un validācijai,\n",
    "- uztrenēsim `segmentation_models_pytorch.Unet` un `segmentation_models_pytorch.FPN`,\n",
    "- salīdzināsim to kvalitāti (loss, IoU/Dice, vizuālie rezultāti)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brabant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
